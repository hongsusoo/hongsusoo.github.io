---
defaults:
  - scope:
      path: ""
      type: posts
    values:
      layout: single
      author_profile: true
      comments: true
      share: true
      related: true

title: "Segmentation Model(Unet,Unet++,Unet3+) 소개"
excerpt: "about : segmentation"
toc: true
toc_sticky: true
toc_label: "Label"
categories:
  - DL
tags:
  - [Segmentation]
date: 2021-10-21
last_modified_at: 2021-10-21
---

<br>

# U-Net

## U-Net 특징

- biomedical image 분야에서 나온 논문으로 2015년 저술된 이후 많은 곳에서 인용되고 있음
- 의료계열에서 사용된 적절한 Deep learning 모델로, 해결해야하는 Task에 잘 맞춰서 해결한 모델
- 의료계에서의 Deep learning 적용이 어려운 이유
    - 의료 계열에서는 데이터가 부족한 경우가 많은데, deep learning의 특성상 네트워크가 깊어 train data가 많이 필요함
    ![image](https://user-images.githubusercontent.com/77658029/139783961-2c134419-6cb8-4c05-8740-2280c123ae85.png)
    - Cell Segmentation작업의 경우 인접한 cell과 같이 동일한 클래스가 붙어있는 경우 구분이 어려움(인접해 있는 셀 사이의 경계 구분이 필요함) → 셀 사이의 경계선을 따로 구분해주는 작업이 필요함
    

## 구조

![image](https://user-images.githubusercontent.com/77658029/139784736-6a14252a-67c9-4e55-933e-7dd800759967.png)

- 대칭으로 이뤄진 Contracting Path(maxpooling)와 Expanding Path(up_conv) 구조

```
U-Net(Contracting Path)의 구조
Layer 1 : [conv→BN→relu→conv→BN→relu] # Padding을 적용하지 않아 사이즈가 감소(size : 572 → 570 → 568), 64channel
Layer 2 : Layer1 output(max pooling) → [conv→BN→relu→conv→BN→relu] # Layer 1과 동일하게 No Padding(size : 284 → 282 → 280), 128 channel
Layer 3 : Layer2 output(max pooling) → [conv→BN→relu→conv→BN→relu] # (size : 140 → 138 → 136), 256 channel
Layer 4 : Layer3 output(max pooling) → [conv→BN→relu→conv→BN→relu] # (size : 68 → 66 → 64), 512 channel
Layer 5 : Layer4 output(max pooling) → [conv→BN→relu→conv→BN→relu] # (size : 32 → 30 → 28), 1024 channel
```

```
U-Net(Expanding Path)의 구조
expanding Layer 4 : (Layer5 output(up_conv, 56x56x512) + Layer4 output(64x64x512→56x56x512 crop) → [conv→BN→relu→conv→BN→relu] # (size : 56 → 54 → 52), 512 channel
expanding Layer 3 : (Layer4 output(up_conv, 104x104x256) + Layer3 output(136x136x256→104x104x256 crop) → [conv→BN→relu→conv→BN→relu] # (size : 104 → 102 → 100), 256 channel
expanding Layer 2 : (Layer3 output(up_conv, 200x200x128) + Layer2 output(280x280x128→200x200x128 crop) → [conv→BN→relu→conv→BN→relu] # (size : 200 → 198 → 196), 128 channel
expanding Layer 1 : (Layer3 output(up_conv, 392x392x64) + Layer2 output(568x568x64→392x392x64 crop) → [conv→BN→relu→conv→BN→relu→conv(1x1)] # (size : 392 → 390 → 388 → 388), 2 channel
```

## Data Augmentation

- Random Elastic Deformation : 물건에 외력을 가한 느낌으로 변형을 주어 세포의 여러 모양을 학습 하게 만들어 robust하게 학습함

## Pixel wise loss weight 적용

- 같은 클래스를 가지는 인접한 셀을 분리하기 위해 경계부분에 가중치를 제공

![image](https://user-images.githubusercontent.com/77658029/139787338-7bd0a814-6777-44f0-9aa0-56bc149fba6e.png)

## U-Net의 한계점

- 깊이가 4로 고정되어 있어 데이터셋마다 최고의 성능을 보장하지 않아 최적 깊이에 대한 탐색 비용이 증가하게됨
- 단순한 Skip connection : 동일한 깊이를 가지는 Encoder와 Decoder만 연결되는 제한된 구조

# U-Net ++

## 특징
- U-Net의 두가지 한계점인 깊이 고정, 단순한 skip connection구조를 개선한 모델
    1. Encoder를 공유하는 다양한 깊이의 U-Net을 생성
    ![image](https://user-images.githubusercontent.com/77658029/139788544-3d4420d1-07f7-4cce-8779-fcddfa34ab19.png)
    2. 다양한 Skip connection 구조
    ![image](https://user-images.githubusercontent.com/77658029/139788159-7ff943e3-653a-4c0f-8a19-9c938664081f.png)
    3. Ensemble 효과
    ![image](https://user-images.githubusercontent.com/77658029/139788797-9fd9bfc9-8411-43a1-9eba-a338910cca50.png)
    
## Hybrid Loss

- pixel wise Cross Entrop와 Soft Dice Coefficient를 함께 사용
- depth에 따른 loss의 평균을 Loss로 사용

![image](https://user-images.githubusercontent.com/77658029/139789649-9f01fd91-d22f-42ff-a078-ef06c985a008.png)

## U-Net ++ 한계점

- 복잡한 connection으로 parameter 수 증가
- 많은 connection으로 인한 Memory 증가
- Encoder-Decoder 사이에서의 Connection이 동일한 크기를 갖는 Feature map에서만 진행됨(Full Scale에서 충분한 정보를 탐색하지 못해 위치와 경계를 명시적으로 학습하지 못함)


# U-Net 3+

## 특징 

- 동일한 크기의 feature map에서만 진행되고, 복잡한 연산을 줄이기 위한 시도들이 추가됨
- 다양한 Feature map 사용 : Full Scale Skip Connections
    - Conventional : Encoder로 부터 Same-Scale의 Feature maps를 받음
    - Inter : Encoder로 부터 Low Level Feature maps를 받음(풍부한 공간정보로 경계 강조)
    - Inter : Decoder로 부터 Larger -Scale의 high level의 Feature maps정보를 받아(위치 정보를 구현)
 
- parameter 수 개선
    - Skip Connection에서 정보를 받아올때 channel 수를 64로 고정하여 전체 Channel이 320 channel이 될 수 있게 고정하여 연산량을 줄임
    ![image](https://user-images.githubusercontent.com/77658029/139791165-4b468525-27d5-45ee-88b4-1c2ce9e25ba3.png)
    
    
## CGM(Classification Guided Module)

- low-level layer에 남아있는 Background noise를 발생하여 많은 False positive 문제를 발생
- 정확도를 높이기 위해 Classification task를 추가적으로 진행하여 argmax를 통해 object가 있으면 1 없으면 0을 곱하는 연산을 진행함

![image](https://user-images.githubusercontent.com/77658029/139791285-8fdf6359-da25-4dd9-894c-e3a2c838044e.png)

## Full Scale Deep Supervision loss

- 경계 부분을 학습하기 위한 여러 Loss 결합
![image](https://user-images.githubusercontent.com/77658029/139791622-a57c9ac3-c9c0-4c4c-ad06-bbd6ca53610f.png)

  
<br><br>

**📌reference**
- boostcourse AI tech
- [U-Net 논문](https://arxiv.org/abs/1505.04597)
- [U-Net++ 논문](https://arxiv.org/abs/1807.10165)
- [U-Net3+ 논문](https://arxiv.org/abs/2004.08790)

<br>

```
💡 수정 필요한 내용은 댓글이나 메일로 알려주시면 감사하겠습니다!💡 
```
