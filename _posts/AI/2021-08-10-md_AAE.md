---
defaults:
  - scope:
      path: ""
      type: posts
    values:
      layout: single
      author_profile: true
      comments: true
      share: true
      related: true

title: "AAE(Adversarial AutoEncoder) model 소개"
excerpt: "about : python"
toc: true
toc_sticky: true
toc_label: "Label"
categories:
  - DL
tags:
  - [DL, AAE]
date: 2021-08-10
last_modified_at: 2021-08-10
---

<br>

# AAE(Adversarial AutoEncoder)

- adversarial Auto Encoder는 VAE와 GAN 두 가지 모델을 결합한 모델

## AE(Auto Encoder)

- Auto Encoder는 Encoder와 Decoder로 구성되어 있음
- Encoder : 입력을 더 낮은 차원 만듦
- Decoder : Encoding된 데이터를 최대한 입력에 가깝게 디코딩하고 재구성하는 방법을 학습하는자가 
- 압축에 사용될 수 있지만, 그냥 압축 알고리즘이 더 효율적이여서 인기가 없음
- 응용 분야 : noise filter(잡음제거), 차원감소, **새로운 데이터 생성**


**💡 AE를 활용한 새 데이터 생성**

1. 도형 1,2,3을 encoding 
2. 한 데이터에서 약간의 변형을 하여 새로운 도형 4를 만듦
3. Decoding하여 새로운 데이터를 생성함

![image](https://user-images.githubusercontent.com/77658029/128884130-f618310d-764e-4f19-90b7-fa3a2e730574.png)

🚨 Issue 사항 : 2번 단계에서 변형에 대한 자유도가 높아 해석이 불가능한 출력이 나올 수 있음

![image](https://user-images.githubusercontent.com/77658029/128885287-79a7569c-232b-445e-9b50-aafde76b31ac.png)

<br>

## VAE(Variational AutoEncoder)

- AE의 이런 Issue 사항을 보완하기 위해 정규화를 진행하여, 새로운 데이터를 만들어줌
- 단일 점(결정적 방식)에 대한 입력이 아닌, 분포(확률적 방식)를 입력으로 하여 최대한 연속적인 데이터를 만들어줌

![image](https://user-images.githubusercontent.com/77658029/128886259-1c00e2c5-e3f8-4678-a477-02bc3f605a47.png)

![0_dwtvGrRWRAUJuZm4](https://user-images.githubusercontent.com/77658029/128886941-8f3e7be4-f620-4065-9574-fc5caac5aec4.gif)


<br>

### AE vs VAE

![image](https://user-images.githubusercontent.com/77658029/128891411-d22b460f-7140-4e28-9e5c-e61931fc467b.png)

<br>

### loss function

- VAE의 Losst function은 MSE(Mean Squared Error)와 KL-divergence 두 가지 항으로 구성되어 있음

![image](https://user-images.githubusercontent.com/77658029/128891648-f5611de7-bedd-4d0a-b1d5-1422808de95c.png)

![image](https://user-images.githubusercontent.com/77658029/128892086-00ea8561-7129-44c8-8cc8-77e76d21952e.png)

- MSE는 단일 항에 대한 Loss를 잡아줌(AE)
- KL-divergence는 분포에 대한 Loss를 잡아줌(VAE)

-> 원래는 $p(z)$인데, 정규분포인 $q(z|x)$를 지정해서, 그 차이를 Loss로 가져감

<br>

## GAN(Generative Adversarial Network)

- 심층 생성 모델링의 접근방식 중 하나
- 지폐 위조범과 경찰이야기
- 지도학습과 비지도학습의 결합(경찰(Discriminator)은 지도학습, 위조범(generator)은 비지도학습)

한 번의 epoch에 일어나는일들

1. Generator(위조지폐범이) 위조지폐를 만든다
2. Discriminator(경찰) 이 위조지폐와 실제 지폐를 구분(위조 - 0, 진짜 - 1)
3. 확률이 50% 이면 종료(완벽한 위조지폐가 생성되면, 확률은 50퍼가 될 것임)

s
![image](https://user-images.githubusercontent.com/77658029/128894266-31f3473b-59d8-4cfe-88b3-e30a1583bb00.png)

-> Generator의 목적은 D(G(z))를 1로 만들려고 노력, Discriminator는  D(x)는 1, D(G(z))는 0을 만드는게 목표

<br>


## AAE(Adversarial AutoEncoder)

- VAE에서는 latent variables를 특정분포로 학습시키기 위해 AE와 KL Divergence를 사용
- AAE에서는 KL Divergence 대신에 GAN를 통한 Discriminator Loss를 사용함
- Discriminator에서 직접 Aggregated Posterior로 Direct back propagation 진행되어 encoder $p(z|x)$를 갱신시켜준다
- encoder $p(z|x)$가 갱신되면, 결국 Aggregated Posterior가 변하게 되고 decoder도 변한상태로 결과가 출력됨

![image](https://user-images.githubusercontent.com/77658029/128899926-20e277a5-43af-4334-b4e9-d30e1545898e.png)

![image](https://user-images.githubusercontent.com/77658029/128899609-cb3fd915-b42f-4dbf-9fee-271e98a74bd0.png)


<br>

추가 확인 필요한 내용
- encoding, decoding 변환을 어떻게 하는지
- back propagation이 어떻게 적용되는지?
- 각각의 network마다 입출력 데이터가 어떻게 되는지 


**📌reference**
- boostcourse AI tech
- [toward data science](https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73)
- [ICHI.PRO](https://ichi.pro/ko/vae-variational-auto-encoder-leul-sayonghan-saengseong-modelling-277371603749134)
- [ICHI.PRO](https://ichi.pro/ko/aae-adversarial-auto-encoder-180304991426392)
- [EuleeKwon's Blog](https://m.blog.naver.com/euleekwon/221557899873)
- [YW & YY](https://greeksharifa.github.io/generative%20model/2020/08/23/AAE/)
- [헤헤](https://cumulu-s.tistory.com/26)

<br>

```
💡 수정 필요한 내용은 댓글이나 메일로 알려주시면 감사하겠습니다!💡 
```
