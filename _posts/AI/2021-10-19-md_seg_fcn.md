---
defaults:
  - scope:
      path: ""
      type: posts
    values:
      layout: single
      author_profile: true
      comments: true
      share: true
      related: true

title: "FCN model - transpose convolution"
excerpt: "about : object detection"
toc: true
toc_sticky: true
toc_label: "Label"
categories:
  - DL
tags:
  - [Segmentation]
date: 2021-10-18
last_modified_at: 2021-10-18
---

<br>

# FCN Fully Convolutaional Network

- VGG ë„¤íŠ¸ì›Œí¬ ë°±ë³¸ì„ ì‚¬ìš©(Feature Extracting Network)
    - Feature Extracting Network(backbone) : VGG, AlexNet, ResNet, EfficienctNet
- VGG ë„¤íŠ¸ì›Œí¬ì˜ FC Layer(nn.Linear)ë¥¼ Convolutionìœ¼ë¡œ ëŒ€ì²´
- Transposed Convolutionì„ ì´ìš©í•˜ì—¬ Pixel Wise Predictionì„ ìˆ˜í–‰í•¨

    
![image](https://user-images.githubusercontent.com/77658029/137853384-f22e6bf6-0acb-4390-97b7-afae0f27d567.png)

![image](https://user-images.githubusercontent.com/77658029/137852646-bde45a44-4087-4e4a-8c34-e539d5c777f3.png)

- ë°±ë³¸ìœ¼ë¡œ VGGë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ !
    - pretrained ëœ ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ -> ì›ë˜ëŠ” ê°€ì¤‘ì¹˜ë¥¼ ìƒˆë¡œ í•™ìŠµì‹œì¼œì•¼í•¨
    - ì—¬ëŸ¬ parameter tuningì— ë“¤ì–´ê°€ëŠ” ìì›ì„ ì•„ë‚„ ìˆ˜ ìˆìŒ

## FC Layer vs FCN

1. ìœ„ì¹˜ì •ë³´ ë³´ì¡´
    - Fully Connected Layerì˜ ê²½ìš° ìœ„ì¹˜ ì •ë³´ê°€ ì§€ì›Œì§€ë‚˜
    - FCNì˜ ê²½ìš° ìœ„ì¹˜ì •ë³´ê°€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆìŒ

![image](https://user-images.githubusercontent.com/77658029/137853729-7c46fdf4-69d5-4d3c-88ce-c09fef4a9064.png)

![image](https://user-images.githubusercontent.com/77658029/137853833-65abd9eb-2e13-448c-a567-c05daeb4f1cc.png)

2. ì…ë ¥ Size
    - FC Layerì˜ ê²½ìš° ì •í•´ì§„ Input Sizeê°€ ì •í•´ì ¸ ìˆìŒ
    - FCNì˜ ê²½ìš° Input Sizeì™€ ìƒê´€ì—†ì´ í•™ìŠµ ë° inferenceê°€ ê°€ëŠ¥í•¨


## Transposed Convolution

- Maxpoolingìœ¼ë¡œ ì¸í•´ì„œ Feature mapì˜ w,hì˜ ì‚¬ì´ì¦ˆê°€ ì‘ì•„ì§€ê²Œ ë˜ëŠ”ë°, ìš°ë¦¬ê°€ ì›í•˜ëŠ” outputì€ imageì˜ ì›ë³¸ ì‚¬ì´ì¦ˆì´ê¸° ë•Œë¬¸ì— upsamplingí•˜ëŠ” ê³¼ì •ì´ í•„ìš”í•œë°, ì´ ì—°ì‚°ì„ ë„ì™€ì£¼ëŠ”ê²Œ Transposed Convolution
- Transposed Convolutionì˜ ì—°ì‚°ë„ Convolutionê³¼ ë™ì¼í•˜ê²Œ Kernelì„ í•™ìŠµí•˜ì—¬ ì‚¬ìš©í•˜ê²Œ ë¨(Backprobagationê³¼ì •ìœ¼ë¡œ updateë¨)


**â“ ì™œ Transposed Convolutionì´ë¼ê³  ë¶€ë¥¼ê¹Œ?**

- ì‚¬ì´ì¦ˆë¥¼ í‚¤ìš´ë‹¤ëŠ” ì˜ë¯¸ë¡œ upsampling, deconvolution, transposed convolutionë“± ì—¬ëŸ¬ê°€ì§€ ìš©ì–´ë¡œ ì„¤ëª…í•˜ê²Œ ë˜ëŠ”ë°, deconvolutionì´ë€ ë‹¨ì–´ëŠ” ë§ì§€ ì•Šë‹¤ê³  í•˜ëŠ” ì‚¬ëŒë“¤ë„ ìˆìŒ
- Transposed Convolution ê³„ì‚° ë°©ë²•

![image](https://user-images.githubusercontent.com/77658029/137856851-13318e66-2f0f-4c62-afc2-37d2db047022.png)

- Transpose Convolutionì´ë¼ê³  ë¶ˆë¦¬ëŠ” ì´ìœ ëŠ” Convolution ì—°ì‚°ì„ Transposedí•œ í˜•íƒœì™€ ë™ì¼í•œ ì—°ì‚° ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒ

![image](https://user-images.githubusercontent.com/77658029/137856702-c580f9aa-e3fb-46fa-9a0c-6614025e429b.png)

- Transposed Convolutionì˜ ê²½ìš° ì™„ë²½í•œ Convolutionë¥¼ ë˜ëŒë¦¬ëŠ” ì—°ì‚°ì´ ì•„ë‹ˆê¸° ë•Œë¬¸ì—Deconvolutionë€ ìš©ì–´ëŠ” ì˜ëª»ëœ í‘œí˜„ì´ì§€ë§Œ, ì—¬ëŸ¬ ë…¼ë¬¸ì´ë‚˜ ì„¤ëª…í•˜ëŠ” ê¸€ì—ì„œ í˜¼ìš©í•˜ì—¬ ì‚¬ìš©í•˜ê³  ìˆìŒ

### Transposed Convolutionì˜ Strideì™€ Padding ë°©ë²•

- Stride 

![image](https://user-images.githubusercontent.com/77658029/139700939-d496e046-a133-4b2b-b6ab-5de7cd75a1f4.png)

- Padding : ì—°ì‚°ì„ ì§„í–‰í•˜ì—¬ ë‚˜ì˜¨ ê²°ê³¼ì— Paddingì„ ì§„í–‰í•¨

![image](https://user-images.githubusercontent.com/77658029/139701230-68335aa1-1f06-429f-8a08-ea3be7ea0e5e.png)

<br>

**ğŸ“°code**
```python
import torch
import torch.nn as nn

x = torch.randn([1, 3, 3, 3])
print(nn.ConvTranspose2d(3, 3, kernel_size=2, stride=1, padding=0)(x).size())
print(nn.ConvTranspose2d(3, 3, kernel_size=2, stride=1, padding=1)(x).size())
print(nn.ConvTranspose2d(3, 3, kernel_size=3, stride=1, padding=0)(x).size())
print(nn.ConvTranspose2d(3, 3, kernel_size=3, stride=1, padding=1)(x).size())
print(nn.ConvTranspose2d(3, 3, kernel_size=2, stride=2, padding=0)(x).size())
```

**ğŸ”result**
```
torch.Size([1, 3, 4, 4])
torch.Size([1, 3, 2, 2])
torch.Size([1, 3, 5, 5])
torch.Size([1, 3, 3, 3])
torch.Size([1, 3, 6, 6])
```

<br>

## ëª¨ë¸ êµ¬ì¡° 

![image](https://user-images.githubusercontent.com/77658029/139704895-2721d55e-ce46-4fa4-9129-4059c00d1605.png)

```
FCN(backbone:VGG)ì˜ êµ¬ì¡°
conv1 : [convâ†’reluâ†’convâ†’reluâ†’maxpool] ì´ë¯¸ì§€ í¬ê¸° inputì˜ 1/2ë¡œ ê°ì†Œ
conv2 : [convâ†’reluâ†’convâ†’reluâ†’maxpool] ì´ë¯¸ì§€ í¬ê¸° inputì˜ 1/4ë¡œ ê°ì†Œ
conv3 : [convâ†’reluâ†’convâ†’reluâ†’convâ†’reluâ†’maxpool] ì´ë¯¸ì§€ í¬ê¸° inputì˜ 1/8ë¡œ ê°ì†Œ
conv4 : [convâ†’reluâ†’convâ†’reluâ†’convâ†’reluâ†’maxpool] ì´ë¯¸ì§€ í¬ê¸° inputì˜ 1/16ë¡œ ê°ì†Œ
conv5 : [convâ†’reluâ†’convâ†’reluâ†’convâ†’reluâ†’maxpool] ì´ë¯¸ì§€ í¬ê¸° inputì˜ 1/32ë¡œ ê°ì†Œ
FC6 : [conv(1Ã—1)â†’reluâ†’dropout]
FC7 : [conv(1Ã—1)â†’reluâ†’dropout]
score : [conv(input_channel, num_classes,1,1,0)]
upscore : [convTransposed2d(num_classes, num_classes, karnel_size=64, stride=32, padding=16)] 
        1/32ê°€ ëœ ì´ë¯¸ì§€ë¥¼ 32ë°° í‚¤ì›Œ ì›ë³¸ ì‚¬ì´ì¦ˆë¡œ ë³µì›
```
- ê²°êµ­ Upsamplingìœ¼ë¡œ ì¸í•œ ë¬¸ì œë¡œ í•´ìƒë„ê°€ ë‚®ìŒ, ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ low levelì˜ feature mapì„ ê°€ì ¸ì™€ í•©ì¹˜ëŠ” ì‘ì—…ì„ ì§„í–‰í•˜ì—¬ ì„±ëŠ¥ì„ í–¥ìƒ ì‹œí‚´

![image](https://user-images.githubusercontent.com/77658029/139705945-58cb7cdf-a4ef-4e01-85dd-8ee5d4b22d18.png)
<br><br>


**ğŸ“Œreference**
- boostcourse AI tech

<br>

```
ğŸ’¡ ìˆ˜ì • í•„ìš”í•œ ë‚´ìš©ì€ ëŒ“ê¸€ì´ë‚˜ ë©”ì¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!ğŸ’¡ 
```
