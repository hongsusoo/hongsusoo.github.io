---
defaults:
  - scope:
      path: ""
      type: posts
    values:
      layout: single
      author_profile: true
      comments: true
      share: true
      related: true

title: "AI Modelì˜ ê²½ëŸ‰í™” í•„ìš”ì„±"
excerpt: "about : ê²½ëŸ‰í™”"
toc: true
toc_sticky: true
toc_label: "Label"
categories:
  - AI ETC
tags:
  - [ê²½ëŸ‰í™”]
date: 2021-11-22
last_modified_at: 2021-11-22
---

<br>

# ê²½ëŸ‰í™” ëª©ì 

- On Device, On Cloud(server)ë¡œ AI ê°€ ëŒì•„ê°€ëŠ” í™˜ê²½ì— ì œì•½ì´ ë§ì•„ì§
- On device limitation
    - power usage(battery)
    - RAM Memory Usage
    - Storage
    - Computing power
- On Cloud limitation
    - Latency
    - Throughput
    - e.g. í•œ ìš”ì²­ì˜ ì†Œìš”ì‹œê°„, ë‹¨ìœ„ ì‹œê°„ë‹¹ ì²˜ë¦¬ ê°€ëŠ¥í•œ ìš”ì²­ìˆ˜
    
â•â“ ë§Œì•½ ê°™ì€ ìì›(=ëˆ, ì‹œê°„)ìœ¼ë¡œ ë” ì ì€ Power usage, Memory Latencyì™€ ë” í° Throughputì´ ê°€ëŠ¥í•˜ë‹¤ë©´

í˜„ì¬ AI ëª¨ë¸ì€ 2012ë…„ ì´í›„ 3,4 ê°œì›”ë§ˆë‹¤ ë‘ë°°ë¡œ ì¦ê°€í•´ì˜´

**ê²½ëŸ‰í™”ëŠ”?**

- ëª¨ë¸ì˜ ì—°êµ¬ì™€ ë³„ê°œë¡œ, ì‚°ì—…ì— ì ìš©ë˜ê¸° ìœ„í•œ í•„ìˆ˜ ê³¼ì •
- ìš”êµ¬ì¡°ê±´(í•˜ë“œì›¨ì–´ ì¢…ë¥˜, Latencyì œí•œ, ìš”êµ¬ Throughput, ì„±ëŠ¥)ë“¤ ê°„ì˜ Trade-offë¥¼ ê³ ë ¤í•˜ì—¬ ëª¨ë¸ ê²½ëŸ‰í™”/ìµœì í™”ë¥¼ ìˆ˜í–‰

## ê²½ëŸ‰í™” ë¶„ì•¼

### ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ê´€ì 

- Efficient Architecture design(+AutoML, NAS(Neural Architecture Search))
    - Softwareì˜ ìƒˆë¡œìš´ ë‹¨ê³„ : Software 1.0 - ì‚¬ëŒì´ ì§œëŠ” ëª¨ë“ˆ, Software 2.0 - ì•Œê³ ë¦¬ì¦˜ì´ ì°¾ëŠ” ëª¨ë“ˆ
        - ì‚¬ëŒì˜ ì§ê´€ë³´ë‹¤ ìƒíšŒí•˜ëŠ” ì„±ëŠ¥ì˜ ëª¨ë“ˆë“¤ì˜ ì°¾ì•„ë‚¼ ìˆ˜ ìˆìŒ
- Network Pruning - í™œë°œí•œ ì—°êµ¬ê°€ ë˜ê³  ìˆì§€ë§Œ, ì¼ë°˜í™” ì–´ë ¤ì›€
    - ì¤‘ìš”ë„ê°€ ë‚®ì€ íŒŒë¼ë¯¸í„° ì œê±°(ì¢‹ì€ ì¤‘ìš”ë„ë¥¼ ì •ì˜í•˜ëŠ” ê²ƒì´ í•˜ë‚˜ì˜ í† í”½)
    - Structured Pruning : ê·¸ë£¹ë‹¨ìœ„ë¡œ Pruningí•˜ëŠ” ê¸°ë²•(Channel/filter,Layer ì „ì²´ë¥¼ Pruning)
    - Unstructured Pruning : íŒŒë¼ë¯¸í„° ê°ê°ì„ ë…ë¦½ì ìœ¼ë¡œ Pruningí•˜ëŠ” ê¸°ë²•, ë‚´ë¶€ì˜ í–‰ë ¬ì´ ì ì  Sparseí•´ì§, Sparse computationì— ìµœì í™”ëœ S/Wí˜¹ì€ H/Wì— ì í•©í•œ ê¸°ë²•
- Knowledge Distillation - í™œë°œí•œ ì—°êµ¬ê°€ ë˜ê³  ìˆì§€ë§Œ, ì¼ë°˜í™” ì–´ë ¤ì›€
    - í•™ìŠµëœ í° ë„¤íŠ¸ì›Œí¬ë¥¼ ì‘ì€ ë„¤íŠ¸ì›Œí¬ì˜ í•™ìŠµë³´ì¡°ë¡œ ì´ìš©í•˜ëŠ” ë°©ë²•
    - ë‹¨ìˆœ ëª¨ë¸ í•™ìŠµì‹œì—ëŠ” Hard target(Ground Truth Label)ê³¼ ë¹„êµí•˜ì—¬ í•™ìŠµí•˜ì§€ë§Œ, Knowledge distillation ë°©ë²•ì„ ì“¸ê²½ìš° ê¸° í•™ìŠµëœ í° ëª¨ë¸ì˜ Soft targetê³¼ Hard Targetì„ í•¨ê»˜ í•™ìŠµí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ë” ë§ì€ ì •ë³´ë¡œ í•™ìŠµí•  ìˆ˜ ìˆìŒ
- Matrix/Tensor Decomposition - ìˆ˜í•™ì ìœ¼ë¡  ë³µì¡í•˜ë‚˜, ê°„ë‹¨í•œ êµ¬í˜„ìœ¼ë¡œ ì¢‹ì€ íš¨ê³¼ê°€ ìˆìŒ
    - í•˜ë‚˜ì˜ Tensorë¥¼ ì‘ì€ Tensorë“¤ì˜ ì¡°í•©ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ê²ƒ
    ![image](https://user-images.githubusercontent.com/77658029/142868840-213d8e5b-79cb-4fd6-a7b2-1e07a7d4400d.png)

### Hardware ê´€ì 

- Network Quantization
    - ì–‘ìí™” : ì¼ë°˜ì ì¸ Float32 ë°ì´í„°ë¥¼ int8, Float16ë“± ì‘ì€ ë°ì´í„° íƒ€ì…ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì—°ì‚° ìˆ˜í–‰í›„ ë³µì›
    - Quantization Errorê°€ ë°œìƒí•˜ê³ , ì¼ë°˜ì ìœ¼ë¡œ ì„±ëŠ¥ì´ ë–¨ì–´ì§
- Network Compiling
    - í•™ìŠµì´ ì™„ë£Œëœ Networkë¥¼ Deployí•˜ë ¤ëŠ” Target Hardwareì—ì„œ Inferenceê°€ ê°€ëŠ¥í•˜ë„ë¡ Compileì§„í–‰
    - ì‚¬ì‹¤ìƒ **ì†ë„ì— ê°€ì¥ í° ì˜í–¥**ì„ ì£¼ëŠ” ê¸°ë²•
    -  e.g. TensorRT(NVIDIA), Tflite(Tensorflow), TVM(apache), ...
    - ê° Libraryë§ˆë‹¤ ì„±ëŠ¥ì°¨ì´ê°€ ë°œìƒ(tfì˜ ê²½ìš° ì•½ 200ê°œì˜ Ruleë¡œ ìµœì í™”ë¥¼ ì§„í–‰í•˜ê²Œë¨)
    - í•˜ì§€ë§Œ, Frameworkì™€ Hardware backends ì‚¬ì´ì˜ ìˆ˜ë§ì€ ì¡°í•©ì´ ìˆì–´ generalized í•˜ê¸° ì–´ë ¤ì›€(Layer Fusion ì¡°í•©ì— ë”°ë¼ ì„±ëŠ¥ ì°¨ì´ê°€ ë°œìƒ)

<br><br><br>

**ğŸ“Œreference**
- boostcourse AI tech

<br>

```
ğŸ’¡ ìˆ˜ì • í•„ìš”í•œ ë‚´ìš©ì€ ëŒ“ê¸€ì´ë‚˜ ë©”ì¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!ğŸ’¡ 
```
