---
defaults:
  - scope:
      path: ""
      type: posts
    values:
      layout: single
      author_profile: true
      comments: true
      share: true
      related: true

title: "[DL Basic] DL Introduction"
excerpt: "about : python"
toc: true
toc_sticky: true
toc_label: "Label"
categories:
  - AI
tags:
  - [python, Deep Learning, AI Model]
date: 2021-08-09
last_modified_at: 2021-08-09
---

<br>

# DL Introduction

ì¢‹ì€ Deep learnerëŠ” ì–´ë–¤ê²ƒ ì¼ê¹Œ?

1. êµ¬í˜„ ìŠ¤í‚¬(tensorflow, torch)
2. ìˆ˜í•™ ëŠ¥ë ¥
3. í˜„ì¬ DL trend(knowing a lot of recent papers)

## ì¸ê³µì§€ëŠ¥(AI)

- ì‚¬ëŒì˜ ì§€ëŠ¥ì„ ëª¨ë°©í•˜ëŠ”ê²ƒ!
- ì¸ê³µì§€ëŠ¥ì˜ í•œ ë¶„ì•¼ë¡œ MLì´ ìˆê³ , ê·¸ ì•ˆì— í•œ ëª¨ë¸ë¡œì¨ Deep Learningì´ ìë¦¬ì¡ê³  ìˆìŒ

![image](https://user-images.githubusercontent.com/77658029/128651883-e08d6147-2f47-44c6-96d5-2382fb6b261d.png)

### Deep Learningì— í•„ìš”í•œ ìš”ì†Œ

1. Data : ì–´ë–¤ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¬ ìˆ˜ ìˆëŠ” ë°ì´í„°ê°€ í•„ìš”
2. Model : Dataë¥¼ ë¶„ì„í•´ì„œ ì–´ë–¤ Labelí™” í•˜ëŠ” ì‘ì—…
3. Loss function : í•™ìŠµì‹œí‚¤ê¸° ìœ„í•œ functionì´ í•„ìš”í•¨ regression ë¬¸ì œì—ì„œ Norm-2 ì‚¬ìš©í•˜ë“¯
4. algorithm : Loss functionì„ ìµœì†Œí™” ì‹œí‚¤ê³ ì í•˜ëŠ” algorithm

ğŸ’¡ ìƒˆë¡œìš´ ì—°êµ¬/ë…¼ë¬¸ì„ ë³¼ë•Œ ìœ„ 4ê°€ì§€ë¥¼ í™•ì¸í•˜ë©´ì„œ ë³´ë©´, ë…¼ë¬¸ì— ëŒ€í•œ ì´í•´ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆìŒ(ê¸°ì¡´ ëŒ€ë¹„ ì–´ë–»ê²Œ ë³€í™”í–ˆëŠ”ì§€)


## Data 

- DataëŠ” ìš°ë¦¬ê°€ í’€ë ¤ê³  í•˜ëŠ” ë¬¸ì œì˜ í˜•íƒœì™€ ê´€ë ¨ì´ ìˆìŒ
    + Classification, Semantic Segmentation, Detection, Pose estimation, Visual QnA
    
    ![image](https://user-images.githubusercontent.com/77658029/128652207-0d2e6787-1f43-4018-98d6-7cea4c4b20fe.png)
    
## Model

![image](https://user-images.githubusercontent.com/77658029/128652228-ab56dd04-04e6-4671-b649-36e07f6c1bfa.png)

## Loss Function 

- ì´ë£¨ê³ ì í•˜ëŠ” Proxy(ê·¼ì‚¬ì¹˜)ì— ë¶ˆê³¼í•¨
- ë‹¨ìˆœíˆ Loss functionì´ ì¤„ì–´ë“œëŠ”ê²Œ ëª©ì ì´ ì•„ë‹˜(ë¬´ì¡°ê±´ ì¤„ì–´ë“ ë‹¤ê³  ë§ëŠ”ê²Œ ì•„ë‹ˆì•¼)
- ì´ Lossê°€ ì¤„ì–´ë“œëŠ”ê²Œ ì§„ì§œ ìš°ë¦¬ê°€ í’€ê³ ì í•˜ëŠ” ë¬¸ì œì˜ ë°©í–¥ì„±ê³¼ ë§ëŠ”ì§€ ì§€ì†ì ìœ¼ë¡ ê³ ë¯¼í•´ì•¼í•¨

![image](https://user-images.githubusercontent.com/77658029/128652276-2f06923a-146e-4842-8e71-6b573b7940e8.png)

## Optimization Algorithm 

- ë§Œë“  ëª¨ë¸ì´ ë‹¨ìˆœ test data ë¿ë§Œ ì•„ë‹ˆë¼ ì‹¤ì œ data ì†ì—ì„œë„ ì˜ ë™ì‘ í•  ìˆ˜ ìˆë„ë¡ í•˜ëŠ” skill

![image](https://user-images.githubusercontent.com/77658029/128652470-940b3445-3a39-455d-80b2-f55126553e48.png)


# Historical Review


2012 - AlexNet : ì´ë¯¸ì§€ ë¶ˆë¥˜ëŒ€íšŒì—ì„œ ì²˜ìŒìœ¼ë¡œ DLì´ ìš°ìŠ¹í•œ ì‹œì 
2013 - DQN : ì•ŒíŒŒê³ 
2014 - Encoder/Decoder
     - Adam Optimizer : ê²°ê³¼ê°€ ì˜ë‚˜ì˜´, ì™ ë§Œí•˜ë©´ ì˜ë‚˜ì˜¨ë‹¤
2015 - GAN(Generative Adversarial Network) : ìˆ ì§‘ ì´ë¦„ì´ ë…¼ë¬¸ ë§ˆì§€ë§‰ì— ë“¤ì–´ê°€ ìˆìŒ(ìˆ ë§ˆì‹œë‹¤ê°€ ë°©ë²•ì´ ë– ì˜¤ë¦„)
     - Resnet : Deep Learningì„ ê°€ëŠ¥í•˜ê²Œ ë§Œë“ ê²ƒ(layerë¥¼ ê¹Šê²Œ ìŒ“ìŒ), ì´ì „ê¹Œì§€ëŠ” 20ë‹¨ì •ë„ ìŒ“ìœ¼ë©´ ë” ì´ìƒ ëª»ìŒ“ëŠ”ë‹¤ ìƒê°í–ˆëŠ”ë°, 100ë‹¨ê¹Œì§€ ìŒ“ì„ ìˆ˜ ìˆëŠ” íŒ¨ëŸ¬ë‹¤ì„ì„ ì œê³µí•¨
2016 - 
2017 - transformer(Attention Is All You Need) : ë§ì€ ë¶€ë¶„ì´ ì´ê±¸ë¡œ ëŒ€ì²´ë˜ê³  ìˆìŒ(RNNë“±ì„ ëŒ€ì²´í•¨)
2018 - Bert(Bidirectional Encoder Representation from Transformers)-fine tuned NLP Models : ì—¬ëŸ¬ ë§ë­‰ì¹˜ë¡œ pretraining ì‹œí‚´
2018 - Big Language Models(GPT-X) : OpenAI, êµ‰ì¥íˆ ë§ì€ 1750ì–µê°œ parametersë¥¼ ì‚¬ìš©í•¨
2020 - Self-Supervised Learning : simCLR (ì‹¬ì‹œì—˜ì•Œ, labelì´ ì—†ëŠ” unsupervied dataë¥¼ ì´ìš©í•¨), ë¹„ì§€ë„í•™ìŠµ,


**ğŸ“Œreference**
- boostcourse AI tech


<br>

```
ğŸ’¡ ìˆ˜ì • í•„ìš”í•œ ë‚´ìš©ì€ ëŒ“ê¸€ì´ë‚˜ ë©”ì¼ë¡œ ì•Œë ¤ì£¼ì‹œë©´ ê°ì‚¬í•˜ê² ìŠµë‹ˆë‹¤!ğŸ’¡ 
```
